{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1PYmnoDWNF4w3eXMjcEdyeHYtJNnZKIgo","authorship_tag":"ABX9TyMhqCRoxKcaWJwwIuiFGEGy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 각종 설정\n","모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언\n","\n","인자(argument)의 역할과 내용\n","- pretrained_model_name : 이전 장에서 파인튜닝한 모델이 사용한 프리트레인 마친 언어모델 이름(단 해당 모델은 허깅페이스 라이브러리에 등록되어 있어야 합니다)\n","- downstream_model_dir : 이전 장에서 파인튜닝한 모델의 체크포인트 저장 위치.\n","- max_seq_length : 토큰 기준 입력 문장 최대 길이. 아무 것도 입력하지 않으면 128입니다."],"metadata":{"id":"CN1wHWOEnc7c"}},{"cell_type":"code","source":["# TPU 관련 패키지 설치\n","\n","!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pythorch\n","/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"],"metadata":{"id":"tiErYqUK9lu5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 의존성 패키지 설치\n","!pip install ratsnlp"],"metadata":{"id":"effcGSHiywTi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 구글 드라이브와 연결\n","from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"],"metadata":{"id":"KflKpjj49bIx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"GKSeyjVa-Sxc","colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"status":"error","timestamp":1690334649260,"user_tz":-540,"elapsed":15363,"user":{"displayName":"윤예은","userId":"04940909667415744758"}},"outputId":"32638899-1bd0-4782-c07f-20863a8d9e06"},"outputs":[{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-886cb321c79d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mratsnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlpbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassificationDeployArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m args = ClassificationDeployArguments(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpretrained_model_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"beomi/kcbert-base\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdownstream_model_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/nlpbook/checkpoint-doccls1-20230726T003135Z-002\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ratsnlp/nlpbook/classification/arguments.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pretrained_model_name, downstream_model_dir, downstream_model_checkpoint_fpath, max_seq_length)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mckpt_file_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mckpt_file_names\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"temp\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"tmp\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_file_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"downstream_model_dir \\\"{downstream_model_dir}\\\" is not valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mselected_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_file_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mmin_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: downstream_model_dir \"/content/drive/MyDrive/nlpbook/checkpoint-doccls1-20230726T003135Z-002\" is not valid"]}],"source":["# 인퍼런스 설정\n","from ratsnlp.nlpbook.classification import ClassificationDeployArguments\n","\n","args = ClassificationDeployArguments(\n","    pretrained_model_name=\"beomi/kcbert-base\",\n","    downstream_model_dir=\"/content/drive/MyDrive/nlpbook/checkpoint-doccls1-20230726T003135Z-002\",\n","    max_seq_length=128,\n",")\n"]},{"cell_type":"markdown","source":["# 모델 로딩\n","파인튜닝을 마친 모델과 토크나이저를 읽어 들입니다.\n","\n","- fine_tuned_model_ckpt['state_dict']: 파인튜닝된 모델의 상태를 가지고 있는 딕셔너리. 모델의 각 레이어에 대한 가중치와 bias 값들 저장\n","- 'model.classifier.bias': 분류기의 bias 텐서를 가져온다.이 분류기는 각 클래스에 대한 확률을 출력하며, bias 텐서 크기는 분류 클래스 수와 동일\n","- .shape.numel(): 텐서의 모든 원소의 개수를 반환. 이 경우에는 bias 텐서의 원소의 개수, 즉 클래스의 수를 반환"],"metadata":{"id":"j5r4A71azfpA"}},{"cell_type":"markdown","source":["# 인퍼런스 함수 선언\n","- 문장(sentence)에 토큰화를 수행한 뒤 input_ids, attention_mask, token_type_ids를 만든다.\n","- 이들 입력값을 파이토치 텐서(tensor) 자료형으로 변환한 뒤 모델에 입력합니다. - 모델 출력 값(outputs.logits)은 소프트맥스 함수 적용 이전의 로짓(logit) 형태인데요. 여기에 소프트맥스 함수를 써서 모델 출력을 [부정일 확률, 긍정일 확률] 형태의 확률 형태로 바꾼다.\n","- 마지막으로 모델 출력을 약간 후처리하여 예측 확률의 최댓값이 부정 위치일 경우 해당 문장이 부정(positive), 반대의 경우 긍정(positive)이 되도록 pred 값을 만든다."],"metadata":{"id":"Hha8RFDNzgpA"}},{"cell_type":"markdown","source":[],"metadata":{"id":"vj38xhfp7tas"}},{"cell_type":"code","source":["!mkdir/root/.ngrok2 && echo \"authtoken: 2T5dfeTEp7iYvvXPnicOeBb78lp_7f3UkTB35MjeK5T4Z31rw\" > /root/.ngrok2/ngrok.yml   # 인증토큰"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgFnZ_hJ8tRj","executionInfo":{"status":"ok","timestamp":1690337305572,"user_tz":-540,"elapsed":8,"user":{"displayName":"윤예은","userId":"04940909667415744758"}},"outputId":"ec4f879b-e9c1-41e4-ff36-9377d4435f47"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: mkdir/root/.ngrok2: No such file or directory\n"]}]}]}